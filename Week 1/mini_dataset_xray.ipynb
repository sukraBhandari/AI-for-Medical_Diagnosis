{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../Data_Entry_2017_v2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_val = pd.read_csv('../train_val_list.txt', header=None, names=['Image Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../test_list.txt', header=None, names=['Image Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = train_and_val.sample(n=1000)\n",
    "temp_train = pd.merge(train_sample, train_df[['Image Index','Finding Labels', 'Patient ID']], on='Image Index')\n",
    "train_dummies = temp_train['Finding Labels'].str.get_dummies('|')\n",
    "t_df = pd.concat([temp_train, train_dummies], axis=1)\n",
    "t_df.drop(['Finding Labels', 'No Finding'], axis=1, inplace=True)\n",
    "t_df.rename(columns = {'Image Index': 'Image', 'Patient ID': 'PatientId'}, inplace=True)\n",
    "t_df.to_csv('../nih/train-small.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112120, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 18)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_sample = train_and_val.sample(n=200)\n",
    "temp_val = pd.merge(val_sample, train_df[['Image Index','Finding Labels', 'Patient ID']], on='Image Index')\n",
    "valid_dummies = temp_val['Finding Labels'].str.get_dummies('|')\n",
    "valid_df = pd.concat([temp_val, valid_dummies], axis=1)\n",
    "valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.columns\n",
    "valid_df.drop(['Finding Labels', 'No Finding'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.rename(columns = {'Image Index': 'Image', 'Patient ID': 'PatientId'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df.to_csv('../nih/valid-small.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = pd.merge(train_sample, train_df[['Image Index','Finding Labels', 'Patient ID']], on='Image Index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_val = pd.merge(val_sample, train_df[['Image Index','Finding Labels', 'Patient ID']], on='Image Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test.sample(n=420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_test = pd.merge(test_sample, train_df[['Image Index','Finding Labels', 'Patient ID']], on='Image Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def check_for_leakage(df1, df2, patient_col):\n",
    "    \"\"\"\n",
    "    Return True if there any patients are in both df1 and df2.\n",
    "\n",
    "    Args:\n",
    "        df1 (dataframe): dataframe describing first dataset\n",
    "        df2 (dataframe): dataframe describing second dataset\n",
    "        patient_col (str): string name of column with patient IDs\n",
    "    \n",
    "    Returns:\n",
    "        leakage (bool): True if there is leakage, otherwise False\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    \n",
    "    df1_patients_unique = set(df1[patient_col].values)\n",
    "    df2_patients_unique = set(df2[patient_col].values)\n",
    "    \n",
    "    patients_in_both_groups = df1_patients_unique.intersection(df2_patients_unique)\n",
    "\n",
    "    # leakage contains true if there is patient overlap, otherwise false.\n",
    "    leakage = len(patients_in_both_groups) > 0 # boolean (true if there is at least 1 patient in both groups)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leakage between train and test: False\n",
      "leakage between valid and test: False\n"
     ]
    }
   ],
   "source": [
    "print(\"leakage between train and test: {}\".format(check_for_leakage(temp_train, temp_test, 'Patient ID')))\n",
    "print(\"leakage between valid and test: {}\".format(check_for_leakage(temp_val, temp_test, 'Patient ID')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dummies = temp_train['Finding Labels'].str.get_dummies('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dummies = temp_val['Finding Labels'].str.get_dummies('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dummies = temp_test['Finding Labels'].str.get_dummies('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([temp_train, train_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.concat([temp_val, valid_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([temp_test, test_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['Finding Labels', 'No Finding'], axis=1, inplace=True)\n",
    "valid_df.drop(['Finding Labels', 'No Finding'], axis=1, inplace=True)\n",
    "test_df.drop(['Finding Labels', 'No Finding'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.rename(columns = {'Image Index': 'Image', 'Patient ID': 'PatientId'}, inplace=True)\n",
    "valid_df.rename(columns = {'Image Index': 'Image', 'Patient ID': 'PatientId'}, inplace=True)\n",
    "test_df.rename(columns = {'Image Index': 'Image', 'Patient ID': 'PatientId'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Image', 'PatientId', 'Atelectasis', 'Cardiomegaly', 'Consolidation',\n",
       "       'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Infiltration', 'Mass',\n",
       "       'Nodule', 'Pleural_Thickening', 'Pneumothorax'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../nih/train-small.csv', index=False)\n",
    "valid_df.to_csv('../nih/valid-small.csv', index=False)\n",
    "test_df.to_csv('../nih/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
